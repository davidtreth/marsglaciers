\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{textcomp}

\hypersetup{colorlinks=true, urlcolor=blue}
%opening
\title{HRSC data processing pipeline documentation}
\author{David Trethewey}

\begin{document}

\maketitle

\begin{abstract}
This is an attempt to document the data processing of the 179 High Resolution 
and Stereo Camera fields used in my 2014 MSc dissertation. The scripts processing the data were written on 
a somewhat ad-hoc basis at the time. To some extent the processing was documented in the dissertation itself, but this document will cover it at a more low level, as well as work done since the dissertation, such as the Top Trumps webpages.
\end{abstract}

\section{Top-level summary of steps.}
This is a list of the steps involved.
\begin{enumerate}
 \item Download the \href{http://www.sciencedirect.com/science/article/pii/S0019103511004131}{Colin Souness 2012 paper}, with the supplementary data, including
 a list of the locations of the 1309 entries in his catalogue of Martian glacier-like forms. 
 \item Identify the HRSC coverage for the locations of the glaciers. This was done during the dissertation manually, using the web 
 interface in the \href{http://ode.rsl.wustl.edu/mars/}{Mars Orbital Data Explorer}, to attempt to identify the HRSC tile that gave the best coverage
 for each Souness glacier. Later on, I made an automated check, using the HRSC DTM coverage shapefile available, along with shapefiles I had generated based on the Souness catalogue.
 This was using the OGR Python API. 
 \item Reproject the ND4 nadir image, and the DA4 areoid elevation to an equirectangular coordinate system, using
 40\textdegree  as the reference latitude. Done using the {\tt gdalwarp} command line program, via scripting in Python
 (the {\tt os.system} library). Resample a copy of the ND4 image to the resolution of the DTM.
 \item Use \href{http://www.landserf.org/}{{\tt LandSerf}} to create the derived topographic variables. Initially \href{http://gdal.org/}{{\tt GDAL}} itself was used, but
 {\tt LandSerf} was thought to offer more as regards the curvature layers. Used Landscript, which was generated by Python.
\item A 10 band layerstack including all the curvature layers was created for each tile, including {\tt LandSerf}'s feature
 classification (1500m window), however in the further analysis a 6 band stack was used, including nadir, dtm,
 slope, aspect (from N), longitudinal curvature, and cross-sectional curvature. This was partly due to processing time, but also because including all of the curvature layers is duplicating the same information. Two different versions were used,
 using the absolute aspect from N, and the raw aspect (which has a discontinuity at 0/360\textdegree.
 The absolute aspect was used for the segmentation, but the raw for zonal stats (check detail of this).
 % check on the detail of this
 \item Add 9999 to make the no data value zero, and avoid negative values of feature layers, which can cause problems with RSGISlib. Done with gdal\_calc.
 \item {\tt RSGISlib} segmentation done - run via Python script for all of the tiles. 
 \item Populate stats to the raster attribute table of the segment clumps output of RSGISlib segmentation.
 \item Export the RAT to a text .csv file. 
 \item Convert to shapefile with gdal\_polygonize. Join stats to output shapefile. (check detail of this). 
 \item Zonal stats for each fields. Heads and extent areas of Souness glaciers.
 \item Collect stats together for all fields.
 \item Compare to overall distribution of variables in the HRSC tiles.
 \item Gaussian fits to histograms, get functions of glacier-like-form abundance for each feature variable.
 \item Create classifier functions.
 \item Visualise in QGIS and do some basic statistical tests.
 \item Subset the ND4 and DA4 images for Top Trumps. Colour the DA4 output with a pseudocolour scheme.
 \item Generate JSON for Top Trumps.
 \item Javascript for Top Trumps webpage.
\end{enumerate}

\section{Downloading data}
Data is obtained from \href{http://ode.rsl.wustl.edu/mars/}{Mars Orbital Data Explorer}, using Data Product Search, selecting under the Mars Express heading `DTMRDR - Digital Terrain Map Reduced Data Record'. Originally when doing this manually, find footprints with `Find by Location or Feature', specifying the latitude and logitude range. When filling in a few gaps where better coverage of a Souness GLF was found, I already know the product ID, so used `Filter by Product ID'.

Use the panchromatic nadir image and the areoid digital terrain model. These are the Product IDs that end in `ND4.IMG' and `DA4.IMG' respectively.
\section{Reprojection and resampling}
\section{Creating derived topographic layers}
\section{Layerstacking}
\section{RSGISlib segmentation}
\section{Populating segment stats}
\section{Convert segments to shapefile, and zonal stats}
\section{Collating the stats}
\section{Creating the classifier function}
\section{Visualisation and statistical tests}
\section{Top Trumps}
\end{document}
